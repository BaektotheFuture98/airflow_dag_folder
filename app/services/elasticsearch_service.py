from app.repositories.elasticsearch_repo import ElasticsearchRepo
from datetime import datetime, timezone
from app.config.logger import get_logger
from app.config.elasticsearch_index import create_index_with_copied_mapping_FINAL
import json

log = get_logger(__name__)

class ElasticsearchService() : 
    def __init__(self, elasticsearchRepo : ElasticsearchRepo) : 
        self.client = elasticsearchRepo
        self.chunk_size = 100000
        self.pagination_size = 100
        self.today_str = datetime.now(timezone.utc).strftime("%Y%m%d")

    def get_chunk_count(self, index: str, query: dict) -> int : 
        count_query = self._query_with_pagination(query)
        total_count = self.client.count(index = index, query = count_query)
        log.info(f"ElasticsearchService: Total count for index={index} is {total_count}")

        num_chunks = (total_count // self.chunk_size) + (1 if total_count % self.chunk_size > 0 else 0)
        log.info(f"ElasticsearchService: Calculated num_chunks={num_chunks} with chunk_size={self.chunk_size}")
        
        if num_chunks == 0 : num_chunks = 1
        return num_chunks
    
    def search(self, index : str, fields:list, query : str, search_after : str) : 
        query = self._query_pagination(query, fields, self.pagination_size, search_after)
        return self.client.search(index=index, query=query)
    
    def _query_pagination(self, query: str, fields : list, page_size: int, search_after:str) -> dict: 
        build_query = {
            "query": {
                "query_string": {
                    "query": query
                }
            },
            "_source": fields,
            "size": page_size,
            "sort": [
                {"kw_docid": {"order": "asc"}}
            ],
            "search_after": [search_after]
        }   
        return build_query
    
    def _query_with_pagination(self, query: str, page_size: int = None, search_after:str = None) -> dict: 
        build_query = {
            "query": {
                "query_string": {
                    "query": query
                }
            }
        }
        
        if search_after :
            build_query["search_after"] = [search_after]
            build_query["size"] = page_size
            build_query["sort"] = [
                {"kw_docid": {"order": "asc"}}
            ]
            
        return build_query
    

    def create_index_before_migration(self, source_index:str, target_index:str) -> bool : 
        source_index = source_index.lower()
        target_index = target_index.lower()
        return create_index_with_copied_mapping_FINAL(self.client.get_client(), source_index, target_index)
        # index_metadata_response = self.client.get_index_mapping(source_index)
        
        # metadata = index_metadata_response[source_index]
        # settings_data = metadata.get('settings', {}).get('index', {})
        # settings_to_copy = {
        #     k: v for k, v in settings_data.items() 
        #     if k not in ['creation_date', 'uuid', 'version', 'provided_name']
        # }

        # mappings_data = metadata.get('mappings', {})

        # if 'analysis' in settings_to_copy : 
        #     analysis_block = settings_to_copy['analysis']
            
        #     normalizer_block = analysis_block.pop('normalizer', None) 
            
        #     if normalizer_block : 
        #         settings_to_copy['analysis'] = {'normalizer':normalizer_block}
        #         log.info("ì„¤ì •: 'analysis' ë¸”ë¡ ì¬êµ¬ì„± ì™„ë£Œ. normalizer ì •ì˜ ìœ ì§€.")
        #     else : 
        #         del settings_to_copy['analysis']
        #         log.info("ì„¤ì •: 'analysis' ë¸”ë¡ ì œê±° ì™„ë£Œ (normalizer ì •ì˜ ì—†ìŒ).")

        # modified_mappings = json.loads(json.dumps(mappings_data))

        # # ì „ì²´ ë§¤í•‘ íŠ¸ë¦¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì œê±°/ì¹˜í™˜ ìˆ˜í–‰
        # self._remove_analyzer_from_mapping(modified_mappings)
        
        # new_index_body = {
        #     "settings": settings_to_copy,
        #     "mappings": modified_mappings 
        # }

        # try:
        #     if self.client.exists(index=target_index):
        #         log.info(f"âš ï¸ ê²½ê³ : ëŒ€ìƒ ì¸ë±ìŠ¤ '{target_index}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        #         return True

        #     creation_response = self.client.create_index(index=target_index, body=new_index_body)
            
        #     if creation_response.get('acknowledged'):
        #         log.info(f"ğŸ‰ ì„±ê³µ: ìƒˆ ì¸ë±ìŠ¤ '{target_index}'ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆê³  ì„¤ì •/ë§¤í•‘ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        #         return True
        #     else:
        #         return False

        # except Exception as e:
        #     print(f"âŒ ì˜¤ë¥˜: ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸ ë°œìƒ: {e}")
        #     return False        

    def _remove_analyzer_from_mapping(self, node):
        """
        ë§¤í•‘ íŠ¸ë¦¬ì—ì„œ íŠ¹ì • analyzer(komoran, cjk, url, whitespace)ë¥¼ ì œê±°í•˜ê±°ë‚˜
        text íƒ€ì…ì¼ ê²½ìš° 'standard'ë¡œ êµì²´.
        dict / list / ê¸°íƒ€ íƒ€ì…ì„ ëª¨ë‘ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬.
        """
        targets = {'komoran', 'cjk', 'url', 'whitespace'}

        # dict ì²˜ë¦¬
        if isinstance(node, dict):
            # í˜„ì¬ ë…¸ë“œì— analyzer í‚¤ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
            if 'analyzer' in node and node.get('analyzer') in targets:
                if node.get('type') == 'text':
                    # text íƒ€ì…ì´ë©´ í‘œì¤€ ë¶„ì„ê¸°ë¡œ êµì²´
                    node['analyzer'] = 'standard'
                else:
                    # ê·¸ ì™¸ íƒ€ì…ì´ë©´ analyzer ì œê±°
                    node.pop('analyzer', None)

            # properties í•˜ìœ„ í•„ë“œ ìˆœíšŒ
            props = node.get('properties')
            if isinstance(props, dict):
                for sub in props.values():
                    self._remove_analyzer_from_mapping(sub)

            # multi-fields (fields) ìˆœíšŒ
            fields = node.get('fields')
            if isinstance(fields, dict):
                for sub in fields.values():
                    self._remove_analyzer_from_mapping(sub)

            # dynamic_templates ìˆœíšŒ (list[ {name: {mapping: {...}}}, ... ])
            dyn = node.get('dynamic_templates')
            if isinstance(dyn, list):
                for tmpl in dyn:
                    if isinstance(tmpl, dict):
                        for tmpl_body in tmpl.values():
                            if isinstance(tmpl_body, dict):
                                mapping = tmpl_body.get('mapping')
                                if mapping:
                                    self._remove_analyzer_from_mapping(mapping)

            # ê¸°íƒ€ í•˜ìœ„ dict/listë„ ë°©ì–´ì  ìˆœíšŒ
            for v in node.values():
                if isinstance(v, (dict, list)):
                    self._remove_analyzer_from_mapping(v)
            return

        # list ì²˜ë¦¬
        if isinstance(node, list):
            for item in node:
                if isinstance(item, (dict, list)):
                    self._remove_analyzer_from_mapping(item)
            return

        # ê·¸ ì™¸ íƒ€ì…(str, int ë“±)ì€ ì²˜ë¦¬ ì—†ìŒ
        return
